Awesome! Letâ€™s move on to LLD Problem 2: LRU Cache â€” one of the most commonly asked system design problems in interviews.

â¸»

âœ… Problem: LRU Cache (Least Recently Used)

ğŸ’¡ What It Is:

An in-memory cache that:
	â€¢	Stores up to N items (capacity)
	â€¢	When full, removes the Least Recently Used item
	â€¢	Provides O(1) access to:
	â€¢	get(key) â†’ returns value
	â€¢	put(key, value) â†’ insert/update key-value pair

â¸»

ğŸ§± Core Requirements

Feature	Requirement
get(key)	Return value if exists, else -1. Mark as most recently used.
put(key, val)	Insert or update key-value. If full, evict LRU item.


â¸»

ğŸ¯ Design Constraints
	â€¢	All operations must be O(1) time
	â€¢	Use doubly linked list + hashmap

â¸»

ğŸ§  High-Level Design

ğŸ“¦ Components
	1.	HashMap â†’ Key â†’ Node (stores key, value)
	2.	Doubly Linked List â†’ Maintains usage order (head = most recent, tail = least recent)

ğŸ” Operations

Operation	Action
get(key)	Move node to head (most recently used)
put(key, value)	Insert/update node, evict tail if over capacity


â¸»

ğŸ§© Class Diagram

LRUCache
 â”œâ”€â”€ capacity: int
 â”œâ”€â”€ cache: Dict[key, Node]
 â”œâ”€â”€ head & tail (Doubly linked list sentinels)

Node
 â”œâ”€â”€ key, value
 â”œâ”€â”€ prev, next


â¸»

âœ… Summary

Concept	Implementation
Access Time	O(1) via hashmap
Order Maintenance	Doubly linked list
Eviction	Remove from tail
Update/Promotion	Move to head


â¸»

ğŸ§  SOLID + Design Patterns

Principle	Application
S	Node (just data), LRUCache (logic)
O	Can replace eviction logic if needed
L	Nodes are generic; interchangeable
I	No bloated interfaces
D	Uses abstraction of node links, not concrete structures

